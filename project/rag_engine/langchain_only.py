from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda, RunnableMap
import os

# ğŸ”¹ LLM êµ¬ì„±
llm = ChatOpenAI(
    temperature=0,
    model="gpt-3.5-turbo",
    api_key=os.getenv("OPENAI_API_KEY")
)

# ğŸ”¹ ì§ˆë¬¸ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ + ì²´ì¸
classifier_prompt = PromptTemplate.from_template("""
ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ë¥˜í•´ì¤˜: "{question}"
- SQL ê´€ë ¨ì´ë©´ "sql"
- ê³ ì¥ ëŒ€ì‘ ê´€ë ¨ì´ë©´ "manual"
- ì „ì²´ ìš”ì•½ì´ë©´ "summary"
ì •ë‹µë§Œ ë§í•´ì¤˜.
""")
classifier_chain = classifier_prompt | llm | RunnableLambda(lambda x: x.content.strip().lower())

# ğŸ”¹ SQL ë¶„ì„ê¸° (ì˜ˆì‹œ)
def run_sql_analysis(question):
    # (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” SQL ìƒì„± + DuckDB ì‹¤í–‰)
    return ["CNC", "MCT"]
sql_chain = RunnableLambda(lambda d: {"machines": run_sql_analysis(d["question"])})

# ğŸ”¹ ë©”ë‰´ì–¼ ê²€ìƒ‰ê¸° (ì˜ˆì‹œ)
def retrieve_manual_chunks(machines):
    return [
        {"machine": m, "status": "ì—ëŸ¬ 3íšŒ, ì •ì§€ 5íšŒ", "manual_chunk": f"[{m}] ì ê²€ í•­ëª©: ì„¼ì„œ, ìœ¤í™œìœ "}
        for m in machines
    ]
manual_chain = RunnableLambda(lambda d: {"chunks": retrieve_manual_chunks(d["machines"])})

# ğŸ”¹ ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸
manual_prompt = PromptTemplate.from_template("""
ê¸°ê³„: {machine}
ìƒíƒœ ìš”ì•½: {status}
ë§¤ë‰´ì–¼ ë‚´ìš©:
{manual_chunk}

ìœ„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì ê²€ í•­ëª©ì„ ì •ë¦¬í•´ì¤˜.
""")
def generate_final_response(data):
    outputs = []
    for item in data["chunks"]:
        prompt = manual_prompt.format(**item)
        res = llm.invoke(prompt)
        outputs.append(f"ğŸ› ï¸ {item['machine']}\n{res.content.strip()}\n")
    return {"response": "\n".join(outputs)}
response_chain = RunnableLambda(generate_final_response)

# ğŸ”¹ summary ì‘ë‹µê¸°
summary_prompt = PromptTemplate.from_template("""
ì˜¤ëŠ˜ì˜ ê¸°ê³„ ë¡œê·¸ ìƒíƒœë¥¼ ìš”ì•½í•´ì¤˜. ì£¼ìš” ì˜¤ë¥˜ ê¸°ê³„, ì‘ë™ë¥ , ì ê²€ í•„ìš” ê¸°ê³„ ë“±ì„ ì •ë¦¬í•´ì¤˜.
ì§ˆë¬¸: {question}
""")
summary_chain = summary_prompt | llm | RunnableLambda(lambda x: {"response": x.content.strip()})

# ğŸ”¹ ìµœì¢… ë¼ìš°í„° ì²´ì¸
full_chain = RunnableMap({
    "type": classifier_chain,
    "question": lambda q: q
}) | (lambda d: {
    "sql": sql_chain | manual_chain | response_chain,
    "manual": manual_chain | response_chain,
    "summary": summary_chain
}[d["type"]])

# ğŸ”¹ ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    question = "ì˜¤ëŠ˜ ì–´ë–¤ ê¸°ê³„ë¥¼ ì ê²€í•´ì•¼ í•˜ê³  ì–´ë–»ê²Œ ì ê²€í•´ì•¼ í•´?"
    result = full_chain.invoke(question)
    print("\n=== ì‘ë‹µ ===\n")
    print(result["response"])

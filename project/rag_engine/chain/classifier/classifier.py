import os
import numpy as np
from sentence_transformers import SentenceTransformer, util
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI

# ğŸ”¹ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ í‚¤ì›Œë“œ
SQL_KEYWORDS = ["ì¿¼ë¦¬", "sql","íšŸìˆ˜ë¥¼ ì•Œë ¤ì¤˜"]
MANUAL_KEYWORDS = ["ë©”ë‰´ì–¼", "ê³ ì¥ ë¶„ì„ ë°©ë²•","ì ê²€ ë°©ë²•","ë§¤ë‰´ì–¼"]
SUMMARY_KEYWORDS = ["ìš”ì•½", "ë³´ê³ ì„œ", "ë¡œê·¸ ìš”ì•½", "ìš´ì „ ë¡œê·¸ ìš”ì•½","ë³´ê³ ì„œ"]

# ğŸ”¹ ì„ë² ë”© ê¸°ë°˜ ëŒ€í‘œ ë¬¸ì¥
prototype_sql = [
    "ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” SQL ì¿¼ë¦¬",
    "ìš´ì „ ë¡œê·¸ë¥¼ í…Œì´ë¸”ë¡œ ë³´ì—¬ì¤˜",
    "ì •ì§€ íšŸìˆ˜ë¥¼ ì•Œë ¤ì¤˜",
    "ì—ëŸ¬ ë¡œê·¸ ê°œìˆ˜ë¥¼ í™•ì¸í•˜ê³  ì‹¶ì–´",
    "1ì›” 29ì¼ ëª‡ ë²ˆ ì •ì§€ëëŠ”ì§€ ì•Œë ¤ì¤˜",
    "SQL ì¿¼ë¦¬ë¡œ ë¶„ì„í•´ì¤˜",
    "SQL"
]

prototype_manual = [
    "ì™œ ê³ ì¥ë‚¬ëŠ”ì§€ ì•Œì•„ë´ì¤˜",
    "ì‘ë™ ì¤‘ ë©ˆì¶˜ ì´ìœ ì™€ ì ê²€ ë°©ë²•",
    "ê¸°ê³„ê°€ ì•ˆ ë¼. ì ê²€ì€ ì–´ë–»ê²Œ í•´?",
    "ì •ë¹„ ë°©ë²•ì´ ì–´ë–»ê²Œ ë¼?",
    "ë©”ë‰´ì–¼ì´ ë­ì•¼?",
    "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´. ì–´ë–»ê²Œ í•´ì•¼ í•´?",
    "ë©”ë‰´ì–¼ì„ ì•Œë ¤ì¤˜",
]

prototype_summary = [
    "1ì›” 29ì¼ ìš´ì „ ë¡œê·¸ ìš”ì•½",
    "1ì›” ì „ì²´ ë¡œê·¸ ìš”ì•½",
    "ìš”ì•½",
    "CNC ìš´ì „ 1ì›” 30ì¼ ë¡œê·¸ ìš”ì•½",
    "ë¡œê·¸ ë¶„ì„",
    "ë³´ê³ ì„œ ì‘ì„±í•´ì¤˜"
]


# ğŸ”¹ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
_model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

# âœ… í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
def classify_by_keyword(question: str) -> str:
    q = question.lower()
    for kw in SQL_KEYWORDS:
        if kw in q:
            return "sql"
    for kw in MANUAL_KEYWORDS:
        if kw in q:
            return "manual"
    for kw in SUMMARY_KEYWORDS:
        if kw in q:
            return "summary"
    return None  # í‚¤ì›Œë“œë¡œ ë¶„ë¥˜í•  ìˆ˜ ì—†ëŠ” ê²½ìš°

# âœ… ì„ë² ë”© ê¸°ë°˜ ë¶„ë¥˜
def classify_by_embedding_pairwise(question: str) -> str:
    q_vec = _model.encode(question)
    sql_vecs = _model.encode(prototype_sql)
    manual_vecs = _model.encode(prototype_manual)
    summary_vecs = _model.encode(prototype_summary)

    sql_score = util.cos_sim(q_vec, sql_vecs).mean().item()
    manual_score = util.cos_sim(q_vec, manual_vecs).mean().item()
    summary_score = util.cos_sim(q_vec, summary_vecs).mean().item()
    print(f"[DEBUG] ì„ë² ë”© ìœ ì‚¬ë„ - SQL: {sql_score}, Manual: {manual_score}, Summary: {summary_score}")
    if summary_score > max(sql_score, manual_score):
        return "summary"
    if sql_score > max(manual_score, summary_score):
        return "sql"
    if manual_score > max(sql_score, summary_score):
        return "manual"
    # ê¸°ë³¸ì ìœ¼ë¡œ SQLê³¼ Manual ë¹„êµ
    if sql_score == manual_score:
        return "manual"  # ë™ë¥ ì¸ ê²½ìš° Manualë¡œ ì²˜ë¦¬
    return "sql" if sql_score > manual_score else "manual"

# âœ… LLM ê¸°ë°˜ ë¶„ë¥˜ê¸° ì²´ì¸ êµ¬ì„±
_llm = ChatOpenAI(
    temperature=0,
    model="gpt-3.5-turbo",
    api_key=os.getenv("OPENAI_API_KEY")
)

_llm_prompt = PromptTemplate.from_template("""
ë‹¤ìŒ ì§ˆë¬¸ì„ "sql", "manual", "summary" ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì¤˜.

ì§ˆë¬¸: "{question}"
ë‹µë³€ (sql/manual/summary ì¤‘ í•˜ë‚˜):
""")

_llm_chain = _llm_prompt | _llm | RunnableLambda(lambda x: x.content.strip().lower())

# âœ… LLM ê¸°ë°˜ ë¶„ë¥˜
def classify_by_llm(question: str) -> str:
    try:
        result = _llm_chain.invoke({"question": question})
        if result in ["sql", "manual", "summary"]:
            return result
    except Exception as e:
        print(f"[ERROR] LLM ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
    return "manual"

# âœ… ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸°
def classify_question_type(question: str, mode: str = "embedding") -> str:
    """
    mode = "keyword" | "embedding" | "llm"
    """
    if mode not in ["keyword", "embedding", "llm"]:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ë¥˜ ëª¨ë“œ: {mode}. 'keyword', 'embedding', 'llm' ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
    
    if not question:
        raise ValueError("ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ìœ íš¨í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    
    print(f"[INFO] ë¶„ë¥˜ ëª¨ë“œ: {mode}, ì§ˆë¬¸: {question}")
    question = question.strip()
    if mode == "keyword":
        return classify_by_keyword(question)

    if mode == "embedding":
        keyword = classify_by_keyword(question)
        if keyword:
            return keyword
        return classify_by_embedding_pairwise(question)

    if mode == "llm":
        return classify_by_llm(question)

    return "manual"

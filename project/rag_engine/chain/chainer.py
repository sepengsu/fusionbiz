# âœ… LangChain-Only ê¸°ë°˜ ì±—ë´‡ êµ¬ì¡° (SQL + ë©”ë‰´ì–¼ + ìš”ì•½)

from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda, RunnableMap
import os

# âœ… ê¸°ì¡´ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
from rag_engine.chain.classifier.classifier import classify_question_type
from rag_engine.chain.execution.sql_executor import run_sql_analysis
from rag_engine.chain.execution.manual_executor import search_manual_chunks

# ğŸ”¹ LLM êµ¬ì„±
llm = ChatOpenAI(
    temperature=0,
    model="gpt-3.5-turbo",
    api_key=os.getenv("OPENAI_API_KEY")
)

# ğŸ”¹ ì§ˆë¬¸ ë¶„ë¥˜ê¸° (í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ê·¸ëŒ€ë¡œ ì‚¬ìš©)
classifier_chain = RunnableLambda(lambda q: {"question": q, "type": classify_question_type(q)})

# ğŸ”¹ SQL ë¶„ì„ê¸° (ê¸°ì¡´ í•¨ìˆ˜ ì—°ê²°)
sql_chain = RunnableLambda(lambda d: {"machines": run_sql_analysis(d["question"])})

# ğŸ”¹ ë©”ë‰´ì–¼ ê²€ìƒ‰ê¸° (ê¸°ì¡´ í•¨ìˆ˜ ì—°ê²°)
manual_chain = RunnableLambda(lambda d: {"chunks": search_manual_chunks(d["machines"])})

# ğŸ”¹ ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸
manual_prompt = PromptTemplate.from_template("""
ê¸°ê³„: {machine}
ìƒíƒœ ìš”ì•½: {status}
ë§¤ë‰´ì–¼ ë‚´ìš©:
{manual_chunk}

ìœ„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì ê²€ í•­ëª©ì„ ì •ë¦¬í•´ì¤˜.
""")

def generate_final_response(data):
    outputs = []
    for item in data["chunks"]:
        prompt = manual_prompt.format(**item)
        res = llm.invoke(prompt)
        outputs.append(f"ğŸ› ï¸ {item['machine']}\n{res.content.strip()}\n")
    return {"response": "\n".join(outputs)}
response_chain = RunnableLambda(generate_final_response)

# ğŸ”¹ summary ì‘ë‹µê¸° (ì˜ˆì‹œìš©)
def generate_summary(question):
    return {"response": "ìš”ì•½ ê¸°ëŠ¥ì€ í˜„ì¬ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤."}
summary_chain = RunnableLambda(generate_summary)

# ğŸ”¹ ìµœì¢… ë¼ìš°í„° ì²´ì¸
full_chain = RunnableMap({
    "type": classifier_chain,
    "question": lambda q: q
}) | (lambda d: {
    "sql": sql_chain | manual_chain | response_chain,
    "manual": manual_chain | response_chain,
    "summary": summary_chain
}[d["type"]])

# ğŸ”¹ ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    question = "ì˜¤ëŠ˜ ì–´ë–¤ ê¸°ê³„ë¥¼ ì ê²€í•´ì•¼ í•˜ê³  ì–´ë–»ê²Œ ì ê²€í•´ì•¼ í•´?"
    result = full_chain.invoke(question)
    print("\n=== ì‘ë‹µ ===\n")
    print(result["response"])
